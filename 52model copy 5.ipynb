{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a465839a",
   "metadata": {
    "id": "a465839a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision.transforms import RandomErasing\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "batch_multi = 2\n",
    "\n",
    "def load_flowers102():\n",
    "    \n",
    "    transformTrain1 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "    transformTrain2 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.5)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "    transformTrain3 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(80),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "    transformTrain4 = transforms.Compose([\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Transform Train 5\n",
    "    transformTrain5 = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomRotation(60),\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Transform Train 6\n",
    "    transformTrain6 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Transform Train 7\n",
    "    transformTrain7 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomRotation(70),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Transform Train 8\n",
    "    transformTrain8 = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Transform Train 9\n",
    "    transformTrain9 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Transform Train 10\n",
    "    transformTrain10 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomRotation(90),\n",
    "    transforms.RandomAffine(degrees=25, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "    transformTest = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "    train_dataset1 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain1)\n",
    "    train_dataset2 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain2)\n",
    "    train_dataset3 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain3)\n",
    "    train_dataset4 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain4)\n",
    "    train_dataset5 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain5)\n",
    "    train_dataset6 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain6)\n",
    "    train_dataset7 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain7)\n",
    "    train_dataset8 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain8)\n",
    "    train_dataset9 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain9)\n",
    "    train_dataset10 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain10)\n",
    "    train_dataset = ConcatDataset([train_dataset1, train_dataset2, train_dataset3, train_dataset4, train_dataset5, train_dataset6, train_dataset7, train_dataset8, train_dataset9, train_dataset10])\n",
    "    test_dataset = torchvision.datasets.Flowers102(root='flowers102data', split='test', download=True, transform=transformTest)\n",
    "    validation_dataset = torchvision.datasets.Flowers102(root='flowers102data', split='val', download=True, transform=transformTest)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=int(32 * batch_multi), shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=int(32 * batch_multi), shuffle=False)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=int(32 * batch_multi), shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, validation_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea7f8df",
   "metadata": {
    "id": "bea7f8df"
   },
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "      print('cuda')\n",
    "      return torch.device(\"cuda\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\") \n",
    "\n",
    "\n",
    "device = set_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5563d5e7",
   "metadata": {
    "id": "5563d5e7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class simpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(1024, 2048, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(2048 * 7 * 7, 1024)  \n",
    "        self.fc2 = nn.Linear(1024, 102) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = self.pool(F.relu(self.conv3(x)))  \n",
    "        x = self.pool(F.relu(self.conv4(x)))  \n",
    "        x = self.pool(F.relu(self.conv5(x)))  \n",
    "        x = x.view(-1, 2048 * 7 * 7)  \n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)  \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2debd59a",
   "metadata": {
    "id": "2debd59a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(model, train_loader, validation_loader, criterion, optimizer, scheduler, patience=5, num_epochs=10):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    current_patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in validation_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(validation_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Training Loss = {avg_train_loss}, Validation Loss = {avg_val_loss}')\n",
    "\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "        print(f\"Current Learning Rate: {current_lr}\")\n",
    "\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            current_patience = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            current_patience += 1\n",
    "            if current_patience >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f42c9fd",
   "metadata": {
    "id": "0f42c9fd"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()  \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_images += labels.size(0)\n",
    "    print(f'Accuracy: {total_correct / total_images * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c0a66d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "35c0a66d",
    "outputId": "508879da-3eaa-4c51-8db8-e7d9dbd6a34d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williampotts/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 4.426758205890655, Validation Loss = 4.181923031806946\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 2: Training Loss = 4.056595873832703, Validation Loss = 3.671804815530777\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 3: Training Loss = 3.6880909368395804, Validation Loss = 3.2378403171896935\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 4: Training Loss = 3.372253453731537, Validation Loss = 2.876242369413376\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 5: Training Loss = 3.0797993019223213, Validation Loss = 2.7570244297385216\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 6: Training Loss = 2.9071844935417177, Validation Loss = 2.573233723640442\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 7: Training Loss = 2.707712236046791, Validation Loss = 2.431636217981577\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 8: Training Loss = 2.55206129103899, Validation Loss = 2.377778336405754\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 9: Training Loss = 2.430953525006771, Validation Loss = 2.2297667413949966\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 10: Training Loss = 2.326830867677927, Validation Loss = 2.2076270058751106\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 11: Training Loss = 2.215719921886921, Validation Loss = 2.187796138226986\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 12: Training Loss = 2.0885367318987846, Validation Loss = 2.189327083528042\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 13: Training Loss = 1.9835339024662972, Validation Loss = 2.117643963545561\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 14: Training Loss = 1.9019821278750897, Validation Loss = 2.061161434277892\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 15: Training Loss = 1.8146061316132545, Validation Loss = 2.1057596672326326\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 16: Training Loss = 1.7098888501524925, Validation Loss = 2.213784608989954\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 17: Training Loss = 1.6642605990171433, Validation Loss = 2.1873344145715237\n",
      "Current Learning Rate: 0.0005\n",
      "Epoch 18: Training Loss = 1.5901648484170436, Validation Loss = 2.0882615372538567\n",
      "Current Learning Rate: 5e-05\n",
      "Epoch 19: Training Loss = 1.3950358390808106, Validation Loss = 2.041606865823269\n",
      "Current Learning Rate: 5e-05\n",
      "Epoch 20: Training Loss = 1.2935529820621015, Validation Loss = 2.0718308091163635\n",
      "Current Learning Rate: 5e-05\n",
      "Epoch 21: Training Loss = 1.3363769136369228, Validation Loss = 2.0662889778614044\n",
      "Current Learning Rate: 5e-05\n",
      "Epoch 22: Training Loss = 1.2771442025899886, Validation Loss = 2.081018963828683\n",
      "Current Learning Rate: 5e-05\n",
      "Epoch 23: Training Loss = 1.2865317367017268, Validation Loss = 2.061165055260062\n",
      "Current Learning Rate: 5e-06\n",
      "Epoch 24: Training Loss = 1.2696210049092769, Validation Loss = 2.0508362222462893\n",
      "Current Learning Rate: 5e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m train_loader, test_loader, validation_loader \u001b[38;5;241m=\u001b[39m load_flowers102()\n\u001b[0;32m----> 8\u001b[0m train_model(model, train_loader, validation_loader, criterion, optimizer, scheduler, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, validation_loader, criterion, optimizer, scheduler, patience, num_epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    160\u001b[0m         group,\n\u001b[1;32m    161\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m         state_steps)\n\u001b[0;32m--> 168\u001b[0m     adam(\n\u001b[1;32m    169\u001b[0m         params_with_grad,\n\u001b[1;32m    170\u001b[0m         grads,\n\u001b[1;32m    171\u001b[0m         exp_avgs,\n\u001b[1;32m    172\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    173\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    174\u001b[0m         state_steps,\n\u001b[1;32m    175\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    176\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    177\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    178\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    179\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    180\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    181\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    182\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    183\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    184\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    185\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    186\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    187\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    188\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 318\u001b[0m func(params,\n\u001b[1;32m    319\u001b[0m      grads,\n\u001b[1;32m    320\u001b[0m      exp_avgs,\n\u001b[1;32m    321\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    322\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    323\u001b[0m      state_steps,\n\u001b[1;32m    324\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    325\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    326\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    327\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    328\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    329\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    330\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    331\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    332\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    333\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    334\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    335\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:441\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    443\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = simpleCNN()\n",
    "model.to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "train_loader, test_loader, validation_loader = load_flowers102()\n",
    "train_model(model, train_loader, validation_loader, criterion, optimizer, scheduler, patience=10, num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1537e0b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1537e0b1",
    "outputId": "9d4295f2-3bb1-4d54-f8e2-78844da47b22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simpleCNN(\n",
       "  (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=100352, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=102, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simpleCNN()\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=torch.device('mps')))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f539cab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f539cab7",
    "outputId": "b516740c-d867-480b-a219-e92e56e1242e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.30%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823e531",
   "metadata": {
    "id": "f823e531"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def test_single_image(model, image_path, transform):\n",
    "    model.eval()  \n",
    "    image = Image.open(image_path)  \n",
    "    image = transform(image).unsqueeze(0)  \n",
    "    image = image.to(device)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb153a3",
   "metadata": {
    "id": "adb153a3",
    "outputId": "29d306e0-7844-4a90-9bfa-e3d4fe92a441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 18\n",
      "Actual Class for image_05954.jpg: 67\n"
     ]
    }
   ],
   "source": [
    "image_path = 'flowers102data/flowers-102/jpg/image_05954.jpg'\n",
    "transformTest = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "model.to(device)  \n",
    "predicted_class = test_single_image(model, image_path, transformTest)\n",
    "print(f'Predicted Class: {predicted_class}')\n",
    "\n",
    "\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "image_directory = 'flowers102data/flowers-102/jpg'\n",
    "label_file = 'imagelabels.mat'\n",
    "\n",
    "\n",
    "image_files = sorted(os.listdir(image_directory))\n",
    "\n",
    "\n",
    "labels_mat = loadmat(label_file)\n",
    "\n",
    "\n",
    "\n",
    "image_name = os.path.basename(image_path)\n",
    "\n",
    "\n",
    "image_index = image_files.index(image_name)\n",
    "\n",
    "actual_label = labels[image_index] -1\n",
    "print(f'Actual Class for {image_name}: {actual_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c44eb577",
   "metadata": {
    "id": "c44eb577"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(71626) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_diagram.png'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simpleCNN().to(device)\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "output = model(dummy_input)\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.format = 'png'\n",
    "dot.render('model_diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791b531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
