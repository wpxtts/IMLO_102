{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a465839a",
      "metadata": {
        "id": "a465839a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision.transforms import RandomErasing\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "\n",
        "batch_multi = 2\n",
        "\n",
        "def load_flowers102():\n",
        "    transformTrain1 = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),  # New affine transformation\n",
        "    #transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # More aggressive blurring\n",
        "    transforms.ToTensor(),\n",
        "    #RandomErasing(0.5, (0.02, 0.33)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "    transformTrain2 = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(50),\n",
        "    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),  # New affine transformation\n",
        "    transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # More aggressive blurring\n",
        "    transforms.ToTensor(),\n",
        "    #RandomErasing(0.5, (0.02, 0.33)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "    transformTrain3 = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomRotation(80),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),  # New affine transformation\n",
        "    #transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # More aggressive blurring\n",
        "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    RandomErasing(0.5, (0.02, 0.33)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "    transformTest = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "    train_dataset1 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain1)\n",
        "    train_dataset2 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain2)\n",
        "    train_dataset3 = torchvision.datasets.Flowers102(root='flowers102data', split='train', download=True, transform=transformTrain3)\n",
        "    train_dataset = ConcatDataset([train_dataset1, train_dataset2, train_dataset3])\n",
        "    test_dataset = torchvision.datasets.Flowers102(root='flowers102data', split='test', download=True, transform=transformTest)\n",
        "    validation_dataset = torchvision.datasets.Flowers102(root='flowers102data', split='val', download=True, transform=transformTest)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32 * batch_multi, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32 * batch_multi, shuffle=False)\n",
        "    validation_loader = DataLoader(validation_dataset, batch_size=32 * batch_multi, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, validation_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bea7f8df",
      "metadata": {
        "id": "bea7f8df"
      },
      "outputs": [],
      "source": [
        "def set_device():\n",
        "    if torch.cuda.is_available():\n",
        "      print('cuda')\n",
        "      return torch.device(\"cuda\")\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\") \n",
        "\n",
        "\n",
        "device = set_device()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5563d5e7",
      "metadata": {
        "id": "5563d5e7"
      },
      "outputs": [],
      "source": [
        "class simpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(simpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(512 * 14 * 14, 1024)  \n",
        "        self.fc2 = nn.Linear(1024, 102)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2debd59a",
      "metadata": {
        "id": "2debd59a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(model, train_loader, validation_loader, criterion, optimizer, scheduler, patience=5, num_epochs=10):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    current_patience = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_train_loss = 0\n",
        "        total_val_loss = 0\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in validation_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        avg_val_loss = total_val_loss / len(validation_loader)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Training Loss = {avg_train_loss}, Validation Loss = {avg_val_loss}')\n",
        "\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "        print(f\"Current Learning Rate: {current_lr}\")\n",
        "\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            current_patience = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            current_patience += 1\n",
        "            if current_patience >= patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Losses')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0f42c9fd",
      "metadata": {
        "id": "0f42c9fd"
      },
      "outputs": [],
      "source": [
        "def test_model(model, test_loader):\n",
        "    model.eval()  \n",
        "    total_correct = 0\n",
        "    total_images = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_images += labels.size(0)\n",
        "    print(f'Accuracy: {total_correct / total_images * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "35c0a66d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "35c0a66d",
        "outputId": "508879da-3eaa-4c51-8db8-e7d9dbd6a34d",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Training Loss = 4.522113213936488, Validation Loss = 4.1984735280275345\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 2: Training Loss = 4.171868329246839, Validation Loss = 3.8294826447963715\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 3: Training Loss = 3.9590850273768106, Validation Loss = 3.6914445012807846\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 4: Training Loss = 3.8071707487106323, Validation Loss = 3.473832204937935\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 5: Training Loss = 3.713669310013453, Validation Loss = 3.3649523556232452\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 6: Training Loss = 3.566900203625361, Validation Loss = 3.217411309480667\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 7: Training Loss = 3.4566436409950256, Validation Loss = 3.0803821682929993\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 8: Training Loss = 3.3410506596167884, Validation Loss = 3.0373274758458138\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 9: Training Loss = 3.1893178621927896, Validation Loss = 2.9252180084586143\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 10: Training Loss = 3.1246886998414993, Validation Loss = 2.857288621366024\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 11: Training Loss = 3.06865664323171, Validation Loss = 2.7941543832421303\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 12: Training Loss = 2.9702662974596024, Validation Loss = 2.7188614830374718\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 13: Training Loss = 2.8954267352819443, Validation Loss = 2.697864405810833\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 14: Training Loss = 2.8371756225824356, Validation Loss = 2.7382913529872894\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 15: Training Loss = 2.8228830049435296, Validation Loss = 2.602166026830673\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 16: Training Loss = 2.716708575685819, Validation Loss = 2.643207147717476\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 17: Training Loss = 2.6873351087172828, Validation Loss = 2.5589333921670914\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 18: Training Loss = 2.664442469676336, Validation Loss = 2.5937868654727936\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 19: Training Loss = 2.598130782445272, Validation Loss = 2.6055040284991264\n",
            "Current Learning Rate: 1e-05\n",
            "Epoch 20: Training Loss = 2.4633444796005883, Validation Loss = 2.476941592991352\n",
            "Current Learning Rate: 1e-05\n",
            "Epoch 21: Training Loss = 2.4121032456556954, Validation Loss = 2.4669850170612335\n",
            "Current Learning Rate: 1e-05\n",
            "Epoch 22: Training Loss = 2.3969678382078805, Validation Loss = 2.4646250382065773\n",
            "Current Learning Rate: 1e-05\n",
            "Epoch 23: Training Loss = 2.3776723792155585, Validation Loss = 2.464373454451561\n",
            "Current Learning Rate: 1e-05\n",
            "Epoch 24: Training Loss = 2.384817977746328, Validation Loss = 2.440469227731228\n",
            "Current Learning Rate: 1e-05\n",
            "Epoch 25: Training Loss = 2.3444820617636046, Validation Loss = 2.440483123064041\n",
            "Current Learning Rate: 1e-05\n",
            "Epoch 26: Training Loss = 2.3667516534527144, Validation Loss = 2.448565252125263\n",
            "Current Learning Rate: 1.0000000000000002e-06\n",
            "Epoch 27: Training Loss = 2.304735471804937, Validation Loss = 2.4454895481467247\n",
            "Current Learning Rate: 1.0000000000000002e-06\n",
            "Epoch 28: Training Loss = 2.301972779134909, Validation Loss = 2.440547153353691\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 29: Training Loss = 2.268380363782247, Validation Loss = 2.4400771968066692\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 30: Training Loss = 2.305378702779611, Validation Loss = 2.439817227423191\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 31: Training Loss = 2.2912438064813614, Validation Loss = 2.4396138414740562\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 32: Training Loss = 2.3329715381066003, Validation Loss = 2.4394019581377506\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 33: Training Loss = 2.3071442196766534, Validation Loss = 2.439352363348007\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 34: Training Loss = 2.2979341397682824, Validation Loss = 2.439140759408474\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 35: Training Loss = 2.3274245684345565, Validation Loss = 2.4387987442314625\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 36: Training Loss = 2.31915661940972, Validation Loss = 2.4388974457979202\n",
            "Current Learning Rate: 1.0000000000000002e-07\n",
            "Epoch 37: Training Loss = 2.242512089510759, Validation Loss = 2.4388370290398598\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 38: Training Loss = 2.275170609354973, Validation Loss = 2.4388310834765434\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 39: Training Loss = 2.290472944577535, Validation Loss = 2.438804727047682\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 40: Training Loss = 2.3107868805527687, Validation Loss = 2.4387560337781906\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 41: Training Loss = 2.264372373620669, Validation Loss = 2.438743144273758\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 42: Training Loss = 2.3039534091949463, Validation Loss = 2.438694652169943\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 43: Training Loss = 2.2951144402225814, Validation Loss = 2.4386759884655476\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 44: Training Loss = 2.3181652004520097, Validation Loss = 2.4386075362563133\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 45: Training Loss = 2.318381438652674, Validation Loss = 2.4385698549449444\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 46: Training Loss = 2.3218726217746735, Validation Loss = 2.438584193587303\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 47: Training Loss = 2.2848085165023804, Validation Loss = 2.4386100620031357\n",
            "Current Learning Rate: 1.0000000000000004e-08\n",
            "Epoch 48: Training Loss = 2.2970405419667563, Validation Loss = 2.4386005364358425\n",
            "Current Learning Rate: 1.0000000000000004e-08\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m train_loader, test_loader, validation_loader \u001b[38;5;241m=\u001b[39m load_flowers102()\n\u001b[0;32m----> 8\u001b[0m train_model(model, train_loader, validation_loader, criterion, optimizer, scheduler, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
            "Cell \u001b[0;32mIn[19], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, validation_loader, criterion, optimizer, scheduler, patience, num_epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     30\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 31\u001b[0m         total_val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     33\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     34\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m total_val_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(validation_loader)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "model = simpleCNN()\n",
        "model.to(device)  \n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1)\n",
        "\n",
        "train_loader, test_loader, validation_loader = load_flowers102()\n",
        "train_model(model, train_loader, validation_loader, criterion, optimizer, scheduler, patience=5, num_epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1537e0b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1537e0b1",
        "outputId": "9d4295f2-3bb1-4d54-f8e2-78844da47b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "simpleCNN(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=100352, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=102, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = simpleCNN()\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f539cab7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f539cab7",
        "outputId": "b516740c-d867-480b-a219-e92e56e1242e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 35.83%\n"
          ]
        }
      ],
      "source": [
        "test_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f823e531",
      "metadata": {
        "id": "f823e531"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def test_single_image(model, image_path, transform):\n",
        "    model.eval()  \n",
        "    image = Image.open(image_path)  \n",
        "    image = transform(image).unsqueeze(0)  \n",
        "    image = image.to(device)  \n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, predicted = torch.max(outputs.data, 1)  \n",
        "    return predicted.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb153a3",
      "metadata": {
        "id": "adb153a3",
        "outputId": "29d306e0-7844-4a90-9bfa-e3d4fe92a441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: 18\n",
            "Actual Class for image_05954.jpg: 67\n"
          ]
        }
      ],
      "source": [
        "image_path = 'flowers102data/flowers-102/jpg/image_05954.jpg'\n",
        "transformTest = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "model.to(device)  \n",
        "predicted_class = test_single_image(model, image_path, transformTest)\n",
        "print(f'Predicted Class: {predicted_class}')\n",
        "\n",
        "\n",
        "import os\n",
        "from scipy.io import loadmat\n",
        "\n",
        "\n",
        "image_directory = 'flowers102data/flowers-102/jpg'\n",
        "label_file = 'imagelabels.mat'\n",
        "\n",
        "\n",
        "image_files = sorted(os.listdir(image_directory))\n",
        "\n",
        "\n",
        "labels_mat = loadmat(label_file)\n",
        "\n",
        "\n",
        "\n",
        "image_name = os.path.basename(image_path)\n",
        "\n",
        "\n",
        "image_index = image_files.index(image_name)\n",
        "\n",
        "actual_label = labels[image_index] -1\n",
        "print(f'Actual Class for {image_name}: {actual_label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c44eb577",
      "metadata": {
        "id": "c44eb577"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
